{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8027344,"sourceType":"datasetVersion","datasetId":4731013}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install wandb\nimport wandb\nwandb.login(key='12c0b23d6865ce943b48c8ea1451c9b2d3aedf60')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:54:54.030973Z","iopub.execute_input":"2024-04-07T16:54:54.031359Z","iopub.status.idle":"2024-04-07T16:54:56.949854Z","shell.execute_reply.started":"2024-04-07T16:54:54.031326Z","shell.execute_reply":"2024-04-07T16:54:56.948902Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom torchvision.transforms import transforms\nfrom torchvision.transforms import RandomRotation, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\nfrom torch.nn import BatchNorm2d, Dropout\nimport numpy as np\n\n# Data transformations with data augmentation\ntransform = transforms.Compose([\n    RandomRotation(degrees=15),  # Random rotations up to 15 degrees\n    RandomHorizontalFlip(),      # Random horizontal flips\n    RandomVerticalFlip(),        # Random vertical flips\n    ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Random color jitter\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Path to iNaturalist dataset directory\ndata_dir = '/kaggle/input/naturalist-data/nature_12K/inaturalist_12K/train'\n\n# Load the iNaturalist dataset and apply transformations\ntrain_dataset = ImageFolder(root=data_dir, transform=transform)\n\n# Define the indices\ndataset_size = len(train_dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(0.2 * dataset_size))  # 20% for validation\n\n# Shuffle indices\nnp.random.seed(42)\nnp.random.shuffle(indices)\n\n# Split the indices into training and validation sets\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# DataLoader instances for training and validation sets\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, sampler=train_sampler)\nval_loader = DataLoader(train_dataset, batch_size=64, sampler=val_sampler)\n\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# Define the path to the iNaturalist dataset directory\ntest_data_dir = '/kaggle/input/naturalist-data/nature_12K/inaturalist_12K/val'\n\n# Define transformations with data augmentation\ntransform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # ImageNet normalization\n])\n\n# Load the iNaturalist dataset using ImageFolder and apply transformations\ntest_dataset = ImageFolder(root=test_data_dir, transform=transform)\n\ntest_loader = DataLoader(test_dataset, batch_size=64)\n\n# print\nfor images, labels in test_loader:\n    print(\"Test batch shapes:\", images.shape, labels.shape)\n    break\n\nfor images, labels in train_loader:\n    print(\"Training batch shapes:\", images.shape, labels.shape)\n    break\n\nfor images, labels in val_loader:\n    print(\"Validation batch shapes:\", images.shape, labels.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:56:47.057895Z","iopub.execute_input":"2024-04-07T16:56:47.058643Z","iopub.status.idle":"2024-04-07T16:57:19.037814Z","shell.execute_reply.started":"2024-04-07T16:56:47.058612Z","shell.execute_reply":"2024-04-07T16:57:19.036616Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Test batch shapes: torch.Size([64, 3, 224, 224]) torch.Size([64])\nTraining batch shapes: torch.Size([64, 3, 224, 224]) torch.Size([64])\nValidation batch shapes: torch.Size([64, 3, 224, 224]) torch.Size([64])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:57:45.192908Z","iopub.execute_input":"2024-04-07T16:57:45.193740Z","iopub.status.idle":"2024-04-07T16:57:45.254767Z","shell.execute_reply.started":"2024-04-07T16:57:45.193709Z","shell.execute_reply":"2024-04-07T16:57:45.253587Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# print('Using device:', device)\n\n# Convolution nueral Network\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10, out_channels=[32, 64, 128, 256, 512], filter_sizes=[3, 3, 3, 3, 3],\n                 stride=1, padding=1, pool_size=(2, 2), fullyconnected_size=128, activations=['relu', 'relu', 'relu', 'relu', 'relu'], dropout_rate=0.2, batch_norm=True, data_augmentation=False):\n        super(CNN, self).__init__()\n\n        # Store arguments as class attributes\n        self.num_classes = num_classes\n        self.out_channels = out_channels\n        self.filter_sizes = filter_sizes\n        self.stride = stride\n        self.padding = padding\n        self.pool_size = pool_size\n        self.fullyconnected_size = fullyconnected_size\n        self.activations = activations\n        self.dropout_rate = dropout_rate\n        self.batch_norm = batch_norm\n        self.data_augmentation = data_augmentation\n\n        # Define the convolutional layers\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.out_channels[0], kernel_size=self.filter_sizes[0],\n                               stride=self.stride, padding=self.padding)\n        self.conv2 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[1],\n                               kernel_size=self.filter_sizes[1], stride=self.stride, padding=self.padding)\n        self.conv3 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[2],\n                               kernel_size=self.filter_sizes[2], stride=self.stride, padding=self.padding)\n        self.conv4 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[3],\n                               kernel_size=self.filter_sizes[3], stride=self.stride, padding=self.padding)\n        self.conv5 = nn.Conv2d(in_channels=self.out_channels[3], out_channels=self.out_channels[4],\n                               kernel_size=self.filter_sizes[4], stride=self.stride, padding=self.padding)\n\n        # Define batch normalization layers\n        if self.batch_norm:\n            self.bn1 = nn.BatchNorm2d(self.out_channels[0])\n            self.bn2 = nn.BatchNorm2d(self.out_channels[1])\n            self.bn3 = nn.BatchNorm2d(self.out_channels[2])\n            self.bn4 = nn.BatchNorm2d(self.out_channels[3])\n            self.bn5 = nn.BatchNorm2d(self.out_channels[4])\n\n        # Dropout layers\n        self.dropout = nn.Dropout2d(p=self.dropout_rate)\n\n        # Calculate the input size for the fully connected layer\n        self._calculate_fc_input_size()\n\n        # Define the fully connected layer\n        self.fc1 = nn.Linear(self.fc_input_size, self.fullyconnected_size)\n\n        # Define the output layer\n        self.fc2 = nn.Linear(self.fullyconnected_size, self.num_classes)\n\n    def forward(self, x):\n        # Convolutional layers with specified activations, batch normalization, dropout, and max pooling\n        x = getattr(F, self.activations[0])(self.conv1(x))\n        if self.batch_norm:\n            x = getattr(F, self.activations[0])(self.bn1(x))\n        if self.data_augmentation:\n            x = F.dropout(x, p=0.2, training=self.training)\n        x = F.max_pool2d(x, kernel_size=self.pool_size, stride=self.pool_size)\n        x = getattr(F, self.activations[1])(self.conv2(x))\n        if self.batch_norm:\n            x = getattr(F, self.activations[1])(self.bn2(x))\n        if self.data_augmentation:\n            x = F.dropout(x, p=0.2, training=self.training)\n        x = F.max_pool2d(x, kernel_size=self.pool_size, stride=self.pool_size)\n        x = getattr(F, self.activations[2])(self.conv3(x))\n        if self.batch_norm:\n            x = getattr(F, self.activations[2])(self.bn3(x))\n        if self.data_augmentation:\n            x = F.dropout(x, p=0.2, training=self.training)\n        x = F.max_pool2d(x, kernel_size=self.pool_size, stride=self.pool_size)\n        x = getattr(F, self.activations[3])(self.conv4(x))\n        if self.batch_norm:\n            x = getattr(F, self.activations[3])(self.bn4(x))\n        if self.data_augmentation:\n            x = F.dropout(x, p=0.2, training=self.training)\n        x = F.max_pool2d(x, kernel_size=self.pool_size, stride=self.pool_size)\n        x = getattr(F, self.activations[4])(self.conv5(x))\n        if self.batch_norm:\n            x = getattr(F, self.activations[4])(self.bn5(x))\n        if self.data_augmentation:\n            x = F.dropout(x, p=0.2, training=self.training)\n        x = F.max_pool2d(x, kernel_size=self.pool_size, stride=self.pool_size)\n\n        # Flatten the output for the fully connected layer\n        x = x.view(-1, self.fc1.in_features)\n\n        # Fully connected layer with ReLU activation\n        x = F.relu(self.fc1(x))\n\n        # Output layer\n        x = self.fc2(x)\n\n        return x\n\n    def _calculate_fc_input_size(self):\n        # Dummy input to calculate the input size for the fully connected layer\n        input_tensor = torch.randn(1, 3, 224, 224)\n        output = self._forward_features(input_tensor)\n        self.fc_input_size = output.view(-1).size(0)\n\n    def _forward_features(self, x):\n        x = F.max_pool2d(getattr(F, self.activations[0])(self.conv1(x)), kernel_size=self.pool_size, stride=self.pool_size)\n        x = F.max_pool2d(getattr(F, self.activations[1])(self.conv2(x)), kernel_size=self.pool_size, stride=self.pool_size)\n        x = F.max_pool2d(getattr(F, self.activations[2])(self.conv3(x)), kernel_size=self.pool_size, stride=self.pool_size)\n        x = F.max_pool2d(getattr(F, self.activations[3])(self.conv4(x)), kernel_size=self.pool_size, stride=self.pool_size)\n        x = F.max_pool2d(getattr(F, self.activations[4])(self.conv5(x)), kernel_size=self.pool_size, stride=self.pool_size)\n        return x\n\n# Create an instance of the CNN model with different configurations\nmodel = CNN(num_classes=10, out_channels=[32, 64, 128, 256, 512], filter_sizes=[3, 3, 3, 3, 3],\n            stride=1, padding=1, pool_size=(2, 2), fullyconnected_size=128,\n            activations=['relu', 'relu', 'relu', 'relu', 'relu'], dropout_rate=0.2, batch_norm=True, data_augmentation=False).to(device)\n\n# Print the model architecture\nprint(model)\n# model.to()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:58:02.951339Z","iopub.execute_input":"2024-04-07T16:58:02.951891Z","iopub.status.idle":"2024-04-07T16:58:03.325995Z","shell.execute_reply.started":"2024-04-07T16:58:02.951862Z","shell.execute_reply":"2024-04-07T16:58:03.325131Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"CNN(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dropout): Dropout2d(p=0.2, inplace=False)\n  (fc1): Linear(in_features=25088, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Define the batch size\n# batch_size = 32\n\n# # Initialize the model\n# model = CNN().to(device)\n\n# # Define the optimizer\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# # Define the loss function\n# criterion = nn.CrossEntropyLoss()\n\n# # Define the number of epochs\n# num_epochs = 1\n\n# # Training loop\n# for epoch in range(num_epochs):\n#     # Set the model to training mode\n#     model.train()\n#     train_loss = 0.0\n#     correct_train = 0\n#     total_train = 0\n\n#     for images, labels in train_loader:\n#         # Move images and labels to device (e.g., GPU)\n#         images, labels = images.to(device), labels.to(device)\n\n#         # Zero the parameter gradients\n#         optimizer.zero_grad()\n\n#         # Forward pass\n#         outputs = model(images)\n\n#         # Calculate loss\n#         loss = criterion(outputs, labels)\n#         train_loss += loss.item()\n\n#         # Backward pass and optimize\n#         loss.backward()\n#         optimizer.step()\n\n#         # Calculate training accuracy\n#         _, predicted = torch.max(outputs.data, 1)\n#         total_train += labels.size(0)\n#         correct_train += (predicted == labels).sum().item()\n\n#     # Calculate average training loss and accuracy\n#     train_loss /= len(train_loader)\n#     train_accuracy = 100 * correct_train / total_train\n\n#     # Set the model to evaluation mode\n#     model.eval()\n#     val_loss = 0.0\n#     correct_val = 0\n#     total_val = 0\n\n#     # Disable gradient calculation\n#     with torch.no_grad():\n#         for images, labels in val_loader:\n#             # Move images and labels to device\n#             images, labels = images.to(device), labels.to(device)\n\n#             # Forward pass\n#             outputs = model(images)\n\n#             # Calculate loss\n#             loss = criterion(outputs, labels)\n#             val_loss += loss.item()\n\n#             # Calculate validation accuracy\n#             _, predicted = torch.max(outputs.data, 1)\n#             total_val += labels.size(0)\n#             correct_val += (predicted == labels).sum().item()\n\n#     # Calculate average validation loss and accuracy\n#     val_loss /= len(val_loader)\n#     val_accuracy = 100 * correct_val / total_val\n\n#     # Print training and validation statistics\n#     print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T18:39:55.119249Z","iopub.execute_input":"2024-04-06T18:39:55.119927Z","iopub.status.idle":"2024-04-06T18:39:55.126145Z","shell.execute_reply.started":"2024-04-06T18:39:55.119893Z","shell.execute_reply":"2024-04-06T18:39:55.125107Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs=4):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     device = 'cuda'\n#     model.to(device)\n    for epoch in range(num_epochs):\n        model.train()  # Set model to train mode\n        running_loss = 0.0\n        train_loss = 0.0\n        correct = 0\n        total = 0\n        for ind, (images, labels) in enumerate(tqdm(train_loader)):\n            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n            optimizer.zero_grad()  # Zero the parameter gradients\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n            train_loss = train_loss + loss\n            loss.backward()  # Backward pass\n            optimizer.step()  # Optimize\n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        train_loss = train_loss / len(train_loader.dataset)\n        train_accuracy = correct / total\n\n        # Validation loop\n        model.eval()  # Set model to evaluation mode\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)  # Move data to GPU\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * images.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        val_loss = val_loss / len(val_loader.dataset)\n        val_accuracy = correct / total\n\n        # Print epoch statistics\n        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n\n        # Log to WandB\n        wandb.log({\n            'epoch': epoch + 1,\n            'train_loss': train_loss,\n            'train_accuracy': train_accuracy,\n            'val_loss': val_loss,\n            'val_accuracy': val_accuracy\n        })\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:58:24.079797Z","iopub.execute_input":"2024-04-07T16:58:24.080580Z","iopub.status.idle":"2024-04-07T16:58:24.093481Z","shell.execute_reply.started":"2024-04-07T16:58:24.080550Z","shell.execute_reply":"2024-04-07T16:58:24.092468Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define the parameters for hyperparameter tuning\nsweep_config = {\n    'method': 'bayes', \n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'filter_sizes': {\n            'values': [[3, 3, 3, 3, 3], [4, 4, 4, 4, 4], [5, 5, 5, 5, 5]]\n        },\n        'activation': {\n            'values': [['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'], ['relu', 'relu', 'relu', 'relu','relu'], ['relu', 'gelu', 'silu', 'mish','relu'],['gelu', 'mish', 'gelu', 'relu','gelu']]\n        },\n        'num_dense': {\n            'values': [128, 256]\n        },\n        'batch_norm': {\n            'values': [True, False]\n        },\n        'filter_organization': {\n            'values': [[64, 128, 256, 512, 1024], [32, 32, 32, 32, 32], [32, 64, 64, 64, 128], [32, 64, 128, 256, 512]]\n        },\n        'dropout_rate': {\n            'values': [0.2, 0.3]  \n        },\n        'data_augmentation': {\n            'values': [True, False] \n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep = sweep_config, project = 'Assignment_2')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:58:47.376447Z","iopub.execute_input":"2024-04-07T16:58:47.376822Z","iopub.status.idle":"2024-04-07T16:58:47.646090Z","shell.execute_reply.started":"2024-04-07T16:58:47.376787Z","shell.execute_reply":"2024-04-07T16:58:47.644942Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Create sweep with ID: khdffvoq\nSweep URL: https://wandb.ai/lokendrakumar/Assignment_2/sweeps/khdffvoq\n","output_type":"stream"}]},{"cell_type":"code","source":"# Now, you can modify your main function to call train_and_evaluate:\ndef main():\n    # Initialize a new wandb run\n    with wandb.init() as run:\n        # Construct run name based on hyperparameters\n        run_name = f\"{wandb.config.activation}-{wandb.config.filter_organization}-dropout-{wandb.config.dropout_rate}-batch_norm-{wandb.config.batch_norm}-data_augmentation-{wandb.config.data_augmentation}\"\n        wandb.run.name = run_name\n\n        # Model object creation\n        model = CNN(num_classes=10,\n                    out_channels=wandb.config.filter_organization,\n                    filter_sizes=wandb.config.filter_sizes,\n                    activations=wandb.config.activation,\n                    fullyconnected_size=wandb.config.num_dense,\n                    dropout_rate=wandb.config.dropout_rate,\n                    data_augmentation=wandb.config.data_augmentation)\n        model.to(device)\n\n#         # Define data transformations with data augmentation\n#         transform = transforms.Compose([\n#             RandomRotation(degrees=15),  # Random rotations up to 15 degrees\n#             RandomHorizontalFlip(),      # Random horizontal flips\n#             RandomVerticalFlip(),        # Random vertical flips\n#             ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Random color jitter\n#             transforms.Resize((224, 224)),\n#             transforms.ToTensor(),\n#             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        \n#         ])\n        # Define data transformations\n        transform_list = [\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ]\n\n        # Conditionally add data augmentation transformations\n        if wandb.config.data_augmentation:\n            transform_list = [\n                RandomRotation(degrees=15),  \n                RandomHorizontalFlip(),   \n                RandomVerticalFlip(),        \n                ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n            ] + transform_list\n\n        transform = transforms.Compose(transform_list)\n        \n        criterion = nn.CrossEntropyLoss()\n        \n\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        train_and_evaluate(model, train_loader, val_loader, criterion, optimizer)\n\n# Run the sweep to perform 5 experiments\nwandb.agent(sweep_id, function=main, count=20)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T06:24:11.346185Z","iopub.execute_input":"2024-04-07T06:24:11.347050Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bszpsaup with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu']\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [4, 4, 4, 4, 4]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m008\u001b[0m (\u001b[33mlokendrakumar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_062413-bszpsaup</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/bszpsaup' target=\"_blank\">jolly-sweep-1</a></strong> to <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/bszpsaup' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/bszpsaup</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 125/125 [10:30<00:00,  5.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4: Train Loss: 0.0313, Train Acc: 0.1754, Val Loss: 0.4413, Val Acc: 0.1731\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:41<00:00,  4.17s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/4: Train Loss: 0.0271, Train Acc: 0.2092, Val Loss: 0.4376, Val Acc: 0.2191\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:39<00:00,  4.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/4: Train Loss: 0.0266, Train Acc: 0.2314, Val Loss: 0.4358, Val Acc: 0.2206\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:36<00:00,  4.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/4: Train Loss: 0.0262, Train Acc: 0.2430, Val Loss: 0.4242, Val Acc: 0.2486\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>train_accuracy</td><td>▁▅▇█</td></tr><tr><td>train_loss</td><td>█▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅█</td></tr><tr><td>val_loss</td><td>█▆▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>0.243</td></tr><tr><td>train_loss</td><td>0.02618</td></tr><tr><td>val_accuracy</td><td>0.24862</td></tr><tr><td>val_loss</td><td>0.42425</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jolly-sweep-1</strong> at: <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/bszpsaup' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/bszpsaup</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_062413-bszpsaup/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rojhhf80 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ['relu', 'relu', 'relu', 'relu', 'relu']\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: [32, 32, 32, 32, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [4, 4, 4, 4, 4]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 256\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_071003-rojhhf80</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/rojhhf80' target=\"_blank\">lyric-sweep-2</a></strong> to <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/rojhhf80' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/rojhhf80</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 125/125 [08:19<00:00,  3.99s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4: Train Loss: 0.0272, Train Acc: 0.2046, Val Loss: 0.4149, Val Acc: 0.2656\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:16<00:00,  3.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/4: Train Loss: 0.0256, Train Acc: 0.2596, Val Loss: 0.4122, Val Acc: 0.2576\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:13<00:00,  3.95s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/4: Train Loss: 0.0250, Train Acc: 0.2801, Val Loss: 0.3938, Val Acc: 0.3057\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:18<00:00,  3.99s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/4: Train Loss: 0.0245, Train Acc: 0.3036, Val Loss: 0.3994, Val Acc: 0.2931\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>train_accuracy</td><td>▁▅▆█</td></tr><tr><td>train_loss</td><td>█▄▂▁</td></tr><tr><td>val_accuracy</td><td>▂▁█▆</td></tr><tr><td>val_loss</td><td>█▇▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>0.30362</td></tr><tr><td>train_loss</td><td>0.02451</td></tr><tr><td>val_accuracy</td><td>0.29315</td></tr><tr><td>val_loss</td><td>0.39938</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lyric-sweep-2</strong> at: <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/rojhhf80' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/rojhhf80</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_071003-rojhhf80/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 87rngbot with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ['relu', 'relu', 'relu', 'relu', 'relu']\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: [32, 32, 32, 32, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [5, 5, 5, 5, 5]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_075200-87rngbot</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/87rngbot' target=\"_blank\">wobbly-sweep-3</a></strong> to <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/87rngbot' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/87rngbot</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 125/125 [08:22<00:00,  4.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4: Train Loss: 0.0276, Train Acc: 0.1903, Val Loss: 0.4345, Val Acc: 0.2226\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:16<00:00,  3.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/4: Train Loss: 0.0260, Train Acc: 0.2544, Val Loss: 0.4208, Val Acc: 0.2541\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:20<00:00,  4.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/4: Train Loss: 0.0252, Train Acc: 0.2764, Val Loss: 0.4035, Val Acc: 0.2931\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:19<00:00,  4.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/4: Train Loss: 0.0247, Train Acc: 0.2920, Val Loss: 0.4001, Val Acc: 0.2826\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>train_accuracy</td><td>▁▅▇█</td></tr><tr><td>train_loss</td><td>█▄▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄█▇</td></tr><tr><td>val_loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>0.292</td></tr><tr><td>train_loss</td><td>0.02475</td></tr><tr><td>val_accuracy</td><td>0.28264</td></tr><tr><td>val_loss</td><td>0.40008</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wobbly-sweep-3</strong> at: <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/87rngbot' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/87rngbot</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_075200-87rngbot/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5fp3x4e8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ['relu', 'relu', 'relu', 'relu', 'relu']\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [4, 4, 4, 4, 4]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_083407-5fp3x4e8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/5fp3x4e8' target=\"_blank\">zany-sweep-4</a></strong> to <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/sweeps/noz2z9yx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/5fp3x4e8' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/5fp3x4e8</a>"},"metadata":{}},{"name":"stderr","text":"100%|██████████| 125/125 [08:34<00:00,  4.12s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/4: Train Loss: 0.0317, Train Acc: 0.1731, Val Loss: 0.4462, Val Acc: 0.1816\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:34<00:00,  4.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/4: Train Loss: 0.0270, Train Acc: 0.2166, Val Loss: 0.4472, Val Acc: 0.1736\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 125/125 [08:28<00:00,  4.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/4: Train Loss: 0.0266, Train Acc: 0.2289, Val Loss: 0.4438, Val Acc: 0.2056\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▍   | 81/125 [05:30<03:00,  4.10s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Model","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_and_test(model, train_loader, test_loader, criterion, optimizer, num_epochs=8):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     device = 'cuda'\n#     model.to(device)\n    for epoch in range(num_epochs):\n        model.train()  # Set model to train mode\n        running_loss = 0.0\n        train_loss = 0.0\n        correct = 0\n        total = 0\n        for ind, (images, labels) in enumerate(tqdm(train_loader)):\n            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n            optimizer.zero_grad()  # Zero the parameter gradients\n            outputs = model(images)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n            train_loss = train_loss + loss\n            loss.backward()  # Backward pass\n            optimizer.step()  # Optimize\n            running_loss += loss.item() * images.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        train_loss = train_loss / len(train_loader.dataset)\n        train_accuracy = correct / total\n\n        # Validation loop\n        model.eval()  # Set model to evaluation mode\n        test_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)  # Move data to GPU\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                test_loss += loss.item() * images.size(0)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        test_loss = test_loss / len(test_loader.dataset)\n        test_accuracy = correct / total\n\n        # Print epoch statistics\n        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, test Loss: {test_loss:.4f}, test Acc: {test_accuracy:.4f}')\n\n        # Log to WandB\n        wandb.log({\n            'epoch': epoch + 1,\n            'train_loss': train_loss,\n            'train_accuracy': train_accuracy,\n            'test_loss': test_loss,\n            'test_accuracy': test_accuracy\n        })\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:00:35.548728Z","iopub.execute_input":"2024-04-07T17:00:35.549561Z","iopub.status.idle":"2024-04-07T17:00:35.562145Z","shell.execute_reply.started":"2024-04-07T17:00:35.549531Z","shell.execute_reply":"2024-04-07T17:00:35.561194Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the parameters for hyperparameter tuning\nbest_sweep_config = {\n    'method': 'bayes', \n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'filter_sizes': {\n            'values': [[3, 3, 3, 3, 3]]\n        },\n        'activation': {\n            'values': [['relu', 'gelu', 'silu', 'mish','relu']]\n        },\n        'num_dense': {\n            'values': [256]\n        },\n        'batch_norm': {\n            'values': [False]\n        },\n        'filter_organization': {\n            'values': [[32, 32, 32, 32, 32]]\n        },\n        'dropout_rate': {\n            'values': [0.3]  \n        },\n        'data_augmentation': {\n            'values': [False] \n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep = best_sweep_config, project = 'Assignment_2')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:01:02.172452Z","iopub.execute_input":"2024-04-07T17:01:02.173395Z","iopub.status.idle":"2024-04-07T17:01:02.432175Z","shell.execute_reply.started":"2024-04-07T17:01:02.173359Z","shell.execute_reply":"2024-04-07T17:01:02.431257Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Create sweep with ID: pgutaejz\nSweep URL: https://wandb.ai/lokendrakumar/Assignment_2/sweeps/pgutaejz\n","output_type":"stream"}]},{"cell_type":"code","source":"# Now, you can modify your main function to call train_and_test:\ndef main():\n    # Initialize a new wandb run\n    with wandb.init() as run:\n        # Construct run name based on hyperparameters\n        run_name = f\"{wandb.config.activation}-{wandb.config.filter_organization}-dropout-{wandb.config.dropout_rate}-batch_norm-{wandb.config.batch_norm}-data_augmentation-{wandb.config.data_augmentation}\"\n        wandb.run.name = run_name\n\n        # Model object creation\n        model = CNN(num_classes=10,\n                    out_channels=wandb.config.filter_organization,\n                    filter_sizes=wandb.config.filter_sizes,\n                    activations=wandb.config.activation,\n                    fullyconnected_size=wandb.config.num_dense,\n                    dropout_rate=wandb.config.dropout_rate,\n                    data_augmentation=wandb.config.data_augmentation)\n        model.to(device)\n        \n        # Define data transformations\n        transform_list = [\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ]\n\n        # Conditionally add data augmentation transformations\n        if wandb.config.data_augmentation:\n            transform_list = [\n                RandomRotation(degrees=15),  # Random rotations up to 15 degrees\n                RandomHorizontalFlip(),      # Random horizontal flips\n                RandomVerticalFlip(),        # Random vertical flips\n                ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Random color jitter\n            ] + transform_list\n\n        transform = transforms.Compose(transform_list)\n        \n        criterion = nn.CrossEntropyLoss()\n        \n\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n            \n        # Train and evaluate the model\n        train_and_test(model, train_loader, test_loader, criterion, optimizer)\n\n# Run the sweep to perform 5 experiments\nwandb.agent(sweep_id, function=main, count=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = CNN(num_classes=10, out_channels=[32, 32, 32, 32, 32], filter_sizes=[3, 3, 3, 3, 3],\n            stride=1, padding=1, pool_size=(2, 2), fullyconnected_size=256,\n            activations=['relu', 'gelu', 'silu', 'mish','relu'], dropout_rate=0.3, batch_norm=False, data_augmentation=False).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:01:13.886212Z","iopub.execute_input":"2024-04-07T17:01:13.886877Z","iopub.status.idle":"2024-04-07T17:01:13.961231Z","shell.execute_reply.started":"2024-04-07T17:01:13.886846Z","shell.execute_reply":"2024-04-07T17:01:13.960207Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Initialize WandB\nwandb.init(project='Assignment_2')\n\n# Function to display a grid of images\ndef display_images(images, predictions, num_cols=3):\n    num_images = len(images)\n    num_rows = int(np.ceil(num_images / num_cols))\n    \n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 3*num_rows))\n    \n    for i, (image, prediction) in enumerate(zip(images, predictions)):\n        ax = axes[i // num_cols, i % num_cols]\n        ax.imshow(image.permute(1, 2, 0))\n        ax.set_title(f'Prediction: {prediction}')\n        ax.axis('off')\n    \n    # Hide any empty subplots\n    for j in range(num_images, num_rows*num_cols):\n        axes[j // num_cols, j % num_cols].axis('off')\n    \n    plt.tight_layout()\n    \n    # Log to WandB\n    wandb.log({\"sample_predictions\": plt})\n    plt.close()\n\n# Function to get sample images and predictions\ndef get_sample_images_and_predictions(best_model, test_loader, num_samples_per_class=3, num_classes=10):\n    best_model.eval()\n    images, predictions = [], []\n    samples_per_class = {cls: 0 for cls in range(num_classes)}  # Keep track of samples per class\n    with torch.no_grad():\n        for i, (image, label) in enumerate(test_loader):\n            for img, lbl in zip(image, label):\n                cls = lbl.item()\n                if samples_per_class[cls] < num_samples_per_class:\n                    output = best_model(img.unsqueeze(0).to(device))\n                    _, prediction = torch.max(output, 1)\n                    predictions.append(prediction.item())\n                    images.append(img)\n                    samples_per_class[cls] += 1\n                if all(val == num_samples_per_class for val in samples_per_class.values()):\n                    break  # Stop when we have enough samples for each class\n            if all(val == num_samples_per_class for val in samples_per_class.values()):\n                break  # Stop when we have enough samples for each class\n    return images, predictions\n\n# Get sample images and predictions for 3 images per class\nsample_images, sample_predictions = get_sample_images_and_predictions(best_model, test_loader, num_samples_per_class=3)\n\n# Display the grid\ndisplay_images(sample_images, sample_predictions, num_cols=3)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:01:35.157332Z","iopub.execute_input":"2024-04-07T17:01:35.157670Z","iopub.status.idle":"2024-04-07T17:03:04.419353Z","shell.execute_reply.started":"2024-04-07T17:01:35.157640Z","shell.execute_reply":"2024-04-07T17:03:04.418305Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m008\u001b[0m (\u001b[33mlokendrakumar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_170135-n6fl6xfh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/n6fl6xfh' target=\"_blank\">sunny-cherry-237</a></strong> to <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/n6fl6xfh' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/n6fl6xfh</a>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_filters(model, test_loader):\n    model.eval()\n    with torch.no_grad():\n        # Get a random image from the test set\n        for images, _ in test_loader:\n            image = images[0].unsqueeze(0).to(device)\n            break\n        \n        # Get the activations of the first convolutional layer\n        activations = model._forward_features(image)\n        \n        # Visualize filters in the first layer\n        num_filters = activations.shape[1]\n        num_cols = 8\n        num_rows = 8  # Ensure 8 rows\n        \n        # Initialize W&B run\n        wandb.init(project=\"Assignment_2\")\n        \n        fig, axes = plt.subplots(num_rows, num_cols, figsize=(30, 30))\n        \n        for i in range(num_rows * num_cols):\n            row = i // num_cols\n            col = i % num_cols\n            if i < num_filters:\n                filter_image = activations[0, i].cpu().numpy()\n                axes[row, col].imshow(filter_image, cmap='gray')\n            else:\n                axes[row, col].axis('off')\n        \n        plt.tight_layout()\n        \n        # Log the figure to wandb\n        wandb.log({\"filters_visualization\": plt})\n        plt.close()\n\n# Visualize filters in the first layer\nvisualize_filters(model, test_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T17:12:53.631253Z","iopub.execute_input":"2024-04-07T17:12:53.631630Z","iopub.status.idle":"2024-04-07T17:13:38.415777Z","shell.execute_reply.started":"2024-04-07T17:12:53.631601Z","shell.execute_reply":"2024-04-07T17:13:38.414806Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:t3bfu83j) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.103 MB of 0.103 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eager-mountain-238</strong> at: <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/t3bfu83j' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/t3bfu83j</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_170336-t3bfu83j/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:t3bfu83j). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_171254-amy9jst9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/amy9jst9' target=\"_blank\">jumping-bush-239</a></strong> to <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lokendrakumar/Assignment_2' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lokendrakumar/Assignment_2/runs/amy9jst9' target=\"_blank\">https://wandb.ai/lokendrakumar/Assignment_2/runs/amy9jst9</a>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}